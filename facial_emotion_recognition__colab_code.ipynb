{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_emotion_recognition _colab_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOttamhH63Jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2242dd75-d26e-4688-95ee-1f0c9c779054"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kf6_wEx65MJ"
      },
      "source": [
        "# 4.2 Data preparation step\n",
        "import pandas as panda\n",
        "import numpy as numpy\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "data_fram = panda.read_csv(\"/content/drive/My Drive/MlF/fer2013.csv\")\n",
        "print(data_fram) #number with disgust emotion [35887 rows x 3 columns]\n",
        "data_frame=data_fram.loc[data_fram['emotion'] != 1]\n",
        "print(data_frame) #number without disgust emotion [35340 rows x 3 columns], we use it in model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bSLI6k-7Zqa"
      },
      "source": [
        "def convert_images_to_gray_scale():\n",
        "    gray_images = data_frame.pixels.apply(convert_from_pixel_array_to_image_array)\n",
        "    gray_images = numpy.stack(gray_images, axis=0)\n",
        "    return gray_images\n",
        "\n",
        "def convert_from_pixel_array_to_image_array(pixel_array):\n",
        "    pixel_array = numpy.array(pixel_array.split(\" \"))\n",
        "    pixel_array = pixel_array.reshape(48, 48, 1)\n",
        "    pixel_array = pixel_array.astype(\"float32\")\n",
        "    return pixel_array\n",
        "\n",
        "def split_data():\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        gray_image, image_label,\n",
        "        test_size=0.2, shuffle=True,\n",
        "        random_state=42, stratify=image_label\n",
        "    )\n",
        "    return X_train, X_valid, y_train, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04DSzdBTugY"
      },
      "source": [
        "gray_image = convert_images_to_gray_scale()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLkEsn6kTzmW"
      },
      "source": [
        "# Making images compatible to the model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "number = LabelEncoder()\n",
        "# Convert the array to class vector, then converts this class vector to binary class matrix\n",
        "image_label = np_utils.to_categorical(number.fit_transform(data_frame.emotion))\n",
        "\n",
        "# Splitting Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = split_data()\n",
        "# Normalize the image arrays using min-max normalization. For gray-scaled images min=0 and max=255\n",
        "X_train = X_train / 255.\n",
        "X_valid = X_valid / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L7HWzdlU1fZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def get_conv2D(filters, kernel_size):\n",
        "    return Conv2D(\n",
        "          filters=filters,\n",
        "          kernel_size=kernel_size,\n",
        "          input_shape=(48, 48, 1),\n",
        "          activation='elu',\n",
        "          padding='same',\n",
        "          kernel_initializer='he_normal'\n",
        "    )\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(get_conv2D(64, (5, 5)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(get_conv2D(64, (5, 5)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(get_conv2D(128, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(get_conv2D(128, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(get_conv2D(256, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(get_conv2D(256, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())    \n",
        "model.add(Dense(128, activation='elu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(6, activation='softmax')) ###\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    steps_per_epoch=len(X_train) / 32,\n",
        "    epochs=200,\n",
        "    use_multiprocessing=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwVE3omIgtj3"
      },
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "sns.set()\n",
        "fig = pyplot.figure(0, (12, 4))\n",
        "\n",
        "ax = pyplot.subplot(1, 2, 1)\n",
        "sns.lineplot(history.epoch, history.history['accuracy'], label='train')\n",
        "sns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.tight_layout()\n",
        "\n",
        "ax = pyplot.subplot(1, 2, 2)\n",
        "sns.lineplot(history.epoch, history.history['loss'], label='train')\n",
        "sns.lineplot(history.epoch, history.history['val_loss'], label='valid')\n",
        "pyplot.title('Loss')\n",
        "pyplot.tight_layout()\n",
        "\n",
        "pyplot.savefig('epoch_history_dcnn.png')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2mq7UDuh02u"
      },
      "source": [
        "# Draw a bar chart representing the count of each emotion\n",
        "sns.countplot(df.emotion)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}